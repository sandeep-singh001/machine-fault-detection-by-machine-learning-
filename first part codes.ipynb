{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab48550f",
      "metadata": {
        "id": "ab48550f",
        "outputId": "f4917956-40e4-4376-a1f4-0f3e9f3fab10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: librosa in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.57.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.0)\n",
            "Requirement already satisfied: appdirs in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->pooch>=1.1->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->pooch>=1.1->librosa) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->pooch>=1.1->librosa) (2023.7.22)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14938be6",
      "metadata": {
        "id": "14938be6",
        "outputId": "366c7a7b-248d-4217-fe07-fe8b37bd98d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "   ---------------------------------------- 0.0/129.1 kB ? eta -:--:--\n",
            "   --------- ----------------------------- 30.7/129.1 kB 660.6 kB/s eta 0:00:01\n",
            "   ------------------ -------------------- 61.4/129.1 kB 656.4 kB/s eta 0:00:01\n",
            "   --------------------------------- ---- 112.6/129.1 kB 819.2 kB/s eta 0:00:01\n",
            "   -------------------------------------- 129.1/129.1 kB 691.3 kB/s eta 0:00:00\n",
            "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92c591f7",
      "metadata": {
        "id": "92c591f7",
        "outputId": "5a9c1dd0-39dd-416a-b330-2221d7b907c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.svm import OneClassSVM\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a89946",
      "metadata": {
        "id": "21a89946"
      },
      "outputs": [],
      "source": [
        "base_dir = 'fan'\n",
        "folders = ['id_00', 'id_02', 'id_04', 'id_06']\n",
        "subfolders = ['abnormal', 'normal']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0068e15a",
      "metadata": {
        "id": "0068e15a"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_name):\n",
        "    y, sr = librosa.load(file_name, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
        "\n",
        "    features = np.concatenate((np.mean(mfccs, axis=1),\n",
        "                               np.mean(chroma, axis=1),\n",
        "                               np.mean(spectral_contrast, axis=1)))\n",
        "    return features\n",
        "\n",
        "def load_data(base_dir, folders, subfolders):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for folder in folders:\n",
        "        for subfolder in subfolders:\n",
        "            path = os.path.join(base_dir, folder, subfolder)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                features = extract_features(file_path)\n",
        "                data.append(features)\n",
        "                labels.append(0 if subfolder == 'normal' else 1)\n",
        "    return np.array(data), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06e455b",
      "metadata": {
        "id": "d06e455b",
        "outputId": "6ca5d358-6aa0-46fb-b918-414d20a92214"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
            "  return pitch_tuning(\n"
          ]
        }
      ],
      "source": [
        "data, labels = load_data(base_dir, folders, subfolders)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f09d599",
      "metadata": {
        "id": "5f09d599"
      },
      "outputs": [],
      "source": [
        "# Using only normal data for training\n",
        "normal_data = data[labels == 0]\n",
        "\n",
        "ocsvm = OneClassSVM(kernel='rbf', gamma='auto')\n",
        "ocsvm.fit(normal_data)\n",
        "\n",
        "# Predict anomalies\n",
        "preds = ocsvm.predict(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c500ca4f",
      "metadata": {
        "id": "c500ca4f",
        "outputId": "cb975616-e78b-4e55-89e2-b178eac29631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-Class SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.96      0.50      0.66      4075\n",
            "    abnormal       0.40      0.94      0.56      1475\n",
            "\n",
            "    accuracy                           0.62      5550\n",
            "   macro avg       0.68      0.72      0.61      5550\n",
            "weighted avg       0.81      0.62      0.63      5550\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict anomalies\n",
        "preds = ocsvm.predict(data)\n",
        "\n",
        "# Map One-Class SVM output to binary classes (0 for normal, 1 for abnormal)\n",
        "mapped_preds = np.where(preds == -1, 1, 0)\n",
        "\n",
        "# One-Class SVM evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"One-Class SVM:\")\n",
        "print(classification_report(labels, mapped_preds, target_names=['normal', 'abnormal']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316bccf7",
      "metadata": {
        "id": "316bccf7",
        "outputId": "18ffc272-9ab0-4f15-f282-953e24fc3296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auto-encoder:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.74      0.96      0.84      4075\n",
            "    abnormal       0.41      0.08      0.13      1475\n",
            "\n",
            "    accuracy                           0.72      5550\n",
            "   macro avg       0.57      0.52      0.48      5550\n",
            "weighted avg       0.65      0.72      0.65      5550\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Auto-encoder evaluation\n",
        "anomaly_preds = np.where(anomalies, 1, 0)\n",
        "print(\"Auto-encoder:\")\n",
        "print(classification_report(labels, anomaly_preds, target_names=['normal', 'abnormal']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6456b95",
      "metadata": {
        "id": "c6456b95"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "# Split the normalized data\n",
        "normal_data_normalized = data_normalized[labels == 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1178d25f",
      "metadata": {
        "id": "1178d25f",
        "outputId": "7e218014-db8a-46e7-97a0-970d7fd7ac1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-Class SVM Test Set Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.78      0.49      0.60       822\n",
            "    abnormal       0.29      0.60      0.39       288\n",
            "\n",
            "    accuracy                           0.52      1110\n",
            "   macro avg       0.53      0.54      0.49      1110\n",
            "weighted avg       0.65      0.52      0.54      1110\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_normalized, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train One-Class SVM on training data\n",
        "ocsvm.fit(X_train[y_train == 0])\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = ocsvm.predict(X_test)\n",
        "mapped_test_preds = np.where(test_preds == -1, 1, 0)\n",
        "\n",
        "# Evaluate on test data\n",
        "print(\"One-Class SVM Test Set Evaluation:\")\n",
        "print(classification_report(y_test, mapped_test_preds, target_names=['normal', 'abnormal']))\n",
        "\n",
        "# Similarly, train and evaluate the auto-encoder model using the training and test sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba9e63a",
      "metadata": {
        "id": "7ba9e63a"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Assuming data_normalized contains your normalized feature data\n",
        "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
        "iso_forest.fit(normal_data_normalized)\n",
        "\n",
        "# Generate predictions\n",
        "iso_preds = iso_forest.predict(data_normalized)\n",
        "\n",
        "# Map predictions: 1 for normal, -1 for outlier/anomalous\n",
        "mapped_iso_preds = np.where(iso_preds == 1, 0, 1)  # Assuming 0 is normal and 1 is abnormal\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}